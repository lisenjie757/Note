# 2.【经典网络】ResNet 论文精读

> 原文链接：[Deep Residual Learning for Image Recognition](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

## 0. 核心总结

核心是提出了一种**残差结构**，极好地解决了网络精度随着深度的增加而下降的问题，使得可以通过堆叠层数的方式来提升精度。

## 1. 摘要

更深的神经网络更难训练，本文提出了一个残差学习框架，以减轻深层神经网络训练的难度。本文将网络的层重构为引入层输入的可学习残差函数，代替了之前为引入层输入的函数。

本文提供了全面的实验证明这些残差网络更容易优化，并且能够从大幅增加的深度中获得准确率增益。在ImageNet数据集上，本文测试了152层的残差网络（比VGG网络深8倍，但具有更低的复杂度），在测试集上达到了3.57%的误差，这个结果赢得了ILSVRC 2015分类任务的第一名。本文也在CIFAR-10数据集上展示了100层和1000层残差网络的分析结果。

网络的深度对于许多视觉识别任务来说是非常重要的，仅仅由于本文实现了极深网络的训练，本文在COCO目标检测数据集上获得了28%的相对提升。深度残差网络也是作者在ImageNet检测、ImageNet定位、COCO检测和COCO分割任务上取得第1名的基础。

## 2. 引言

卷积神经网络的深度是非常重要的，之前在ImageNet数据集上取得领先结果的经典模型都从深度上受益，但是现在深度卷积神经网络正面临臭名昭著的梯度消失/爆炸问题。

虽然这个问题目前可以通过Normalization来解决，但却又出现了退化问题：随着网络深度的增加，精度达到饱和，然后迅速退化，即**更深的网络精度反而下降**。这种退化并不是由过拟合引起的，因为训练误差同样增高，实验结果如下图：

![不同层数卷积神经网络的训练和测试误差](https://i.imgur.com/pnZMQpr.png)

根据朴素的直觉，即使更深的网络的深层部分“什么都不做”，即输出是输入的恒等映射，深层网络起码也不应该比浅层网络的误差高，但这样的实验结果表明目前的优化器找不到这样的解。

因此，本文引入了一个残差块来解决退化问题，如下图所示，残差块的核心是通过一个捷径连接（Shortcut Connections，或叫做残差连接）跳过一层或多层卷积将输出增加到层的输出中，添加一个输入的恒等映射。

用数学公式表达，即我们希望让卷积层拟合一个残差映射 $F(x)+x$ ，而不是原映射 $F(x)$ ，因为通过实验发现卷积层这样的非线性层很难拟合一个恒等映射，所以我们直接增加一个恒等映射。

![残差块结构示意图](https://i.imgur.com/VFWqkqe.png)

通过在ImageNet数据集上的全面实验表明：

1. 本文的深度残差网络更易于优化，相比简单堆叠的“普通网络”有更低的训练误差；
2. 本文的深度残差网络可以很容易得从大幅增加的深度中获得精度增益，产出的结果明显优于以前的网络。

本文也在CIFAR-10数据集上做了同样的测试，得到了同样的优异的精度表现，并探索训练了超过1000层的模型。

我们训练的152层残差网络在ImageNet测试集上取得了3.57%的top-5误差，同时仍比VGG网络有更低的复杂度，赢得了ILSVRC 2015分类竞赛的第一名；极深的网络在其它识别任务上也具有出色的泛化性能，在ILSVRC和COCO 2015竞赛中进一步获得第1名（ImageNet检测、ImageNet定位、COCO检测和COCO分割）。这表明残差学习的原理具有普适性，它在其他视觉和非视觉问题中也是同样适用的。

## 3. ResNet网络细节

### 3.1 如何增加残差连接

在数学公式上，残差块的定义如下：

$$y = F(x,\{W_i\}) + x$$

其中， $x,y$ 分别为层的输入和输出向量，函数 $F(x,\{W_i\})$ 表示要学习的残差映射。

例如，对于上一幅图所示的两层残差块， $F = W_2 \cdot ReLU(W_1x)$ ，为了简化表示此处省略了偏差（Bias）。接着，残差连接通过 $F + x$ 操作逐元素相加来实现，相加后再通过一层ReLU输入下一个残差块。

此外需要注意，在等式中 $x$ 和 $F$ 的维度必须相等，若不相等则可以通过一个线性投影 $W_s$ 来匹配维度，如下式：

$$y = F(x,\{W_i\}) + W_s x$$