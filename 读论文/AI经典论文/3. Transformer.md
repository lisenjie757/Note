# 3.【新神经网络架构】Transformer 论文精读

> 原文链接：[Attention Is All You Need](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)

## 0. 核心总结

核心是提出了一种**残差结构**，极好地解决了网络精度随着深度的增加而下降的问题，使得可以通过堆叠层数的方式来提升精度。

## 1. 摘要

本文提出了一个全新的网络架构，称为Transformer，完全基于注意力机制，完全摒弃了卷积和循环神经网络。通过多个机器翻译实验表明，本文的Transformer模型在精度上更优，同时可以并行化计算和需要的训练时间更少。在WMT2014英德翻译任务上取得了28.4个BLEU，比包括集成模型在内的最好结果高了2个BLEU以上。

![屏幕截图 2023-04-13 023046](https://i.imgur.com/VHXz0Mr.png)

## 2. 引言

RNN、LSTM、GRU是此前最为先进的序列模型，但是由于其顺序计算的特性，无法并行化。注意力机制（Attention）的提出，使得可以在不同位置之间建立长距离的依赖关系，从而可以并行化计算，通常这类注意力机制都与循环网络结合使用。

在本文的工作中，提出了一种Transformer结构，完全依靠注意力机制来绘制输入和输出之间的全局依赖关系。Transformer支持更多的并行化计算，在8个P100 GPU上训练短短12个小时后就可以达到翻译质量的先进水平。

## 3. Transformer模型结构

Transformer模型的整体结构如下图所示，编码器和解码器都使用堆叠的**自注意力（Self-attention）**和**逐点全连接层（Point-wise fully connected layers）**，分别如图的左半部分和右半部分所示：

![Transformer模型结构](https://i.imgur.com/couWgCO.png)

大多数先进的序列模型都有编码器-解码器结构，在Transformer中，编码器将输入序列 $(x_1,\ldots,x_n)$ 映射为一个连续的表示 $\pmb{z}=(z_1,\ldots,z_n)$ , 给定 $\pmb{z}$ ，解码器逐个生成输出序列 $(y_1,\ldots,y_m)$ ，一次一个元素，在每一次，模型都是自回归的，即在生成下一个元素 $y_i$ 时，模型都是输入之前生成的元素 $y_1,\ldots,y_{i-1}$ 作为额外的输入。

### 3.1 编码器和解码器块细节

- **编码器（Encoder）**：编码器由 $N=6$ 个相同的层堆叠而成，每层包含两个子层。第一层是一个**多头自注意力机制（Multi-head self-attention）**，第二层是一个简单的**逐点全连接前馈网络（Point-wise fully connected feed-forward network）**。每个子层都有一个残差连接，然后是一个层归一化（Layer Normalization）。

### 3.2 网络架构

下图展示了34层的ResNet架构，并与34层的“普通”网络及VGG-19的结构对比：

![ResNet-34架构与其它架构的对比](https://i.imgur.com/hhl8lxx.png)

下表给出了ResNet架构的更多细节及更多变体：

![ResNet不同架构的配置](https://i.imgur.com/Oz8YCZD.png)

其中，对于50层以上的深层网络，为了降低其计算复杂度，本文设计了一种瓶颈架构（Bottleneck），如下图所示。即先通过一个1×1的卷积先降低维度，再通过具有较小输入和输出维度的3×3卷积瓶颈，最后再通过一个1×1的卷积恢复维度。通过这样的瓶颈设计可以有效地减少模型的参数两和复杂度。

![屏幕截图 2023-03-26 103814](https://i.imgur.com/iOc24tZ.png)

### 3.3 网络训练细节

1. 数据增强：对图像的短边在[256,480]中随机采样进行尺度缩放；对图像或其随机翻转进行224×224的随机剪裁采样，并减去每个像素的均值；标准颜色增强。
2. 在每次卷积之后、激活之前采用批归一化（Batch Normalization）。
3. 初始化权重从头开始训练，使用SGD优化器，批大小（Batch Size）为256；学习率从0.1开始，当loss不再下降时除以10；最多训练 $60 \times 10^4$ 个迭代（iteration）；权重衰减（Weight Decay）为0.0001，动量（Momentum）为0.9；不使用Dropout。
4. （为了刷榜，没多大必要）在测试时采用标准的10-crop测试，为了获得最佳结果，采用全卷积网络形式，并在多尺度图像上取平均精度（对图像的短边进行缩放在{224,256,384,480,640}中取值）。

## 4. 实验与结果

本文在由1000个类组成的ImageNet-2012分类数据集上进行评估。模型在128万张训练集图像上进行训练，在5万张验证集图像上进行测试，得到top-1和top-5错误率。

下表对比了不同层数的ResNet和普通网络在ImageNet验证集上的Top-1误差：

![ResNet和普通网络的对比](https://i.imgur.com/LQorajE.png)

下图展示了它们在训练过程中的训练/验证误差：

![ResNet和普通网络的训练过程](https://i.imgur.com/OKkMSIU.png)

上述图表结果均表明，普通网络的精度随着深度的增加反而会退化，而ResNet则可以从增加的深度中获得精度增益，同时可以发现，ResNet的收敛速度会比普通网络更快。

本文还研究了三种恒等映射方式：

1. A：使用补零的方式来实现维度匹配；
2. B：不同维度则使用线性投影来实现维度匹配，相同维度则直接相加；
3. C：不论维度是否匹配均使用线性投影。

实验结果如下表所示，下表为10-crop测试结果，可以发现C略优于B，优于A，但使用C会导致参数量和复杂度过大，所以接下来的实验均采用B方案。

![不同网络架构的10-crop测试结果](https://i.imgur.com/lfMBvg5.png)

此外，上表还展示了ResNet-50/101/152三种深层ResNet架构的测试结果，可以发现没有出现退化现象，均从深度中获得了精度增益。

下表展示了单模型的测试结果，得到的结论是相同的。

![不同网络架构的单模型测试结果](https://i.imgur.com/HBlhfBt.png)

此外，上述两个测试结果表均展示与之前SOTA单模型的对比结果，可以发现ResNet-50就由于之前所有的SOTA单模型。

本文还将6个不同深度的ResNet模型进行集成（两个152层，其余深度各一个），这个集成模型的精度最优，在ILSVRC 2015竞赛中取得了第一名，测试结果如下表所示，下表为与ImageNet测试集上排名前5的模型的对比结果：

![与ImageNet测试集排名前5的模型的对比结果](https://i.imgur.com/RDubP6g.png)

## 5. 个人思考

此前的卷积神经网络架构一直在追求更深的深度，因为能够从增加的深度中获得精度增益，但当深度到了某一界限，更深的层非但没有起作用，反而起了副作用，出现了梯度消失/爆炸的现象。

本文揭示了发生这种现象的本质原因是由于我们目前的优化器很难去优化到一个恒等映射，即输出对于输入总会发生一定程度的偏移，随着深度的增加，这种偏移会离最优解越偏越远，因此本文将前几层输入信息引入下一层，增加了下一层输入恒等映射的权重，让下一层有选择拟合恒等映射的空间。

个人的另一种理解是，神经网络的深层神经元会“遗忘”神经网络浅层的特征信息，所以需要通过不断加入浅层信息的方式去“提醒”深层的神经元这个输入的底层特征，来帮助深层神经元做出更优的推断。
