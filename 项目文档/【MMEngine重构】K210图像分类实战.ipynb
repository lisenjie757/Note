{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【MMEngine重构】K210图像分类实战"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torchvision\n",
    "from mmengine.model import BaseModel\n",
    "import torch\n",
    "\n",
    "class MobileNet(BaseModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        def conv_dw(in_channels, out_channels, kernel_size, strides, padding):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, in_channels, kernel_size, strides, padding, groups=in_channels, bias=False),\n",
    "                nn.BatchNorm2d(in_channels), nn.ReLU6(inplace=True),\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False), \n",
    "                nn.BatchNorm2d(out_channels), nn.ReLU6(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=1, bias=False), \n",
    "                nn.BatchNorm2d(out_channels), nn.ReLU6(inplace=True))\n",
    "        self.features = nn.Sequential(\n",
    "            conv_dw(1,32,kernel_size=3,strides=2,padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            conv_dw(32,64,kernel_size=3,strides=2,padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            conv_dw(64,128,kernel_size=3,strides=1,padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            conv_dw(128,10,kernel_size=3,strides=1,padding=1),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "    def forward(self, imgs, labels=None, mode='predict'):\n",
    "        x = self.features(imgs)\n",
    "        if mode == 'loss':\n",
    "            return {'loss': nn.CrossEntropyLoss()(x, labels)}\n",
    "        elif mode == 'predict':\n",
    "            return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1900f8a8a90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 超参数设置\n",
    "epochs = 20\n",
    "batch_size_train = 64\n",
    "batch_size_test = 64\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "\n",
    "# 训练配置\n",
    "num_workers = 12\n",
    "log_interval = 10\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 构建数据集和数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.Resize(224),\n",
    "                      transforms.ToTensor(),\n",
    "                  ])),\n",
    "    batch_size=batch_size_train, shuffle=True, num_workers=num_workers\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.Resize(224),\n",
    "                      transforms.ToTensor(),\n",
    "                  ])),\n",
    "    batch_size=batch_size_test, shuffle=True, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 构建评测指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.evaluator import BaseMetric\n",
    "\n",
    "class Accuracy(BaseMetric):\n",
    "    def process(self, data_batch, data_samples):\n",
    "        score, gt = data_samples\n",
    "        # 将一个批次的中间结果保存至 `self.results`\n",
    "        self.results.append({\n",
    "            'batch_size': len(gt),\n",
    "            'correct': (score.argmax(dim=1) == gt).sum().cpu(),\n",
    "        })\n",
    "\n",
    "    def compute_metrics(self, results):\n",
    "        total_correct = sum(item['correct'] for item in results)\n",
    "        total_size = sum(item['batch_size'] for item in results)\n",
    "        # 返回保存有评测指标结果的字典，其中键为指标名称\n",
    "        return dict(accuracy=100 * total_correct / total_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 构建执行器并执行任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/27 20:19:17 - mmengine - INFO - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 295416231\n",
      "    GPU 0: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "    CUDA_HOME: None\n",
      "    GCC: n/a\n",
      "    PyTorch: 2.0.0\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 199711\n",
      "  - MSVC 193431937\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.0\n",
      "    OpenCV: 4.7.0\n",
      "    MMEngine: 0.7.2\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: None\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "04/27 20:19:18 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "04/27 20:19:18 - mmengine - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "runner = Runner(\n",
    "    # 用以训练和验证的模型，需要满足特定的接口需求\n",
    "    model=MobileNet(),\n",
    "    # 工作路径，用以保存训练日志、权重文件信息\n",
    "    work_dir='./work_dir',\n",
    "    # 训练数据加载器，需要满足 PyTorch 数据加载器协议\n",
    "    train_dataloader=train_dataloader,\n",
    "    # 优化器包装，用于模型优化，并提供 AMP、梯度累积等附加功能\n",
    "    optim_wrapper=dict(optimizer=dict(type=SGD, lr=lr, momentum=momentum)),\n",
    "    # 训练配置，用于指定训练周期、验证间隔等信息\n",
    "    train_cfg=dict(by_epoch=True, max_epochs=epochs, val_interval=1),\n",
    "    # 验证数据加载器，需要满足 PyTorch 数据加载器协议\n",
    "    val_dataloader=test_dataloader,\n",
    "    # 验证配置，用于指定验证所需要的额外参数\n",
    "    val_cfg=dict(),\n",
    "    # 用于验证的评测器，这里使用默认评测器，并评测指标\n",
    "    val_evaluator=dict(type=Accuracy),\n",
    ")\n",
    "\n",
    "#runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (tinynn.converter.base) Generated model saved to ./epoch_20.tflite\n"
     ]
    }
   ],
   "source": [
    "from tinynn.converter import TFLiteConverter\n",
    "import os\n",
    "\n",
    "checkpoint = torch.load('./work_dir/epoch_20.pth')\n",
    "model = MobileNet()\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "\n",
    "dummy_input = torch.rand((1, 1, 224, 224))\n",
    "\n",
    "output_path = os.path.join('./epoch_20.tflite')\n",
    "\n",
    "# When converting quantized models, please ensure the quantization backend is set.\n",
    "#torch.backends.quantized.engine = 'qnnpack'\n",
    "\n",
    "# The code section below is used to convert the model to the TFLite format\n",
    "# If you want perform dynamic quantization on the float models,\n",
    "# you may refer to `dynamic.py`, which is in the same folder.\n",
    "# As for static quantization (e.g. quantization-aware training and post-training quantization),\n",
    "# please refer to the code examples in the `examples/quantization` folder.\n",
    "converter = TFLiteConverter(model, dummy_input, output_path)\n",
    "converter.convert()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
