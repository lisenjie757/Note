{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19dbc65b",
   "metadata": {},
   "source": [
    "# K210从训练到部署实战"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde47ae",
   "metadata": {},
   "source": [
    "## 0. 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f057e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms, utils, models\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 若检测到有GPU则使用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed6ed35",
   "metadata": {},
   "source": [
    "## 1. 各类辅助函数操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92523712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorg降采样操作\n",
    "class reorg_layer(nn.Module):\n",
    "    def __init__(self, stride):\n",
    "        super(reorg_layer, self).__init__()\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        _height, _width = height // self.stride, width // self.stride\n",
    "        \n",
    "        x = x.view(batch_size, channels, _height, self.stride, _width, self.stride).transpose(3, 4).contiguous()\n",
    "        x = x.view(batch_size, channels, _height * _width, self.stride * self.stride).transpose(2, 3).contiguous()\n",
    "        x = x.view(batch_size, channels, self.stride * self.stride, _height, _width).transpose(1, 2).contiguous()\n",
    "        x = x.view(batch_size, -1, _height, _width)\n",
    "\n",
    "        return x\n",
    "\n",
    "# iou分数计算\n",
    "def iou_score(bboxes_a, bboxes_b):\n",
    "    \"\"\"\n",
    "        bbox_1 : [B*N, 4] = [x1, y1, x2, y2]\n",
    "        bbox_2 : [B*N, 4] = [x1, y1, x2, y2]\n",
    "    \"\"\"\n",
    "    tl = torch.max(bboxes_a[:, :2], bboxes_b[:, :2])\n",
    "    br = torch.min(bboxes_a[:, 2:], bboxes_b[:, 2:])\n",
    "    area_a = torch.prod(bboxes_a[:, 2:] - bboxes_a[:, :2], 1)\n",
    "    area_b = torch.prod(bboxes_b[:, 2:] - bboxes_b[:, :2], 1)\n",
    "\n",
    "    en = (tl < br).type(tl.type()).prod(dim=1)\n",
    "    area_i = torch.prod(br - tl, 1) * en  # * ((tl < br).all())\n",
    "    return area_i / (area_a + area_b - area_i)\n",
    "\n",
    "# loss计算\n",
    "class MSEWithLogitsLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MSEWithLogitsLoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits, targets, mask):\n",
    "        inputs = torch.clamp(torch.sigmoid(logits), min=1e-4, max=1.0 - 1e-4)\n",
    "\n",
    "        # 被忽略的先验框的mask都是-1，不参与loss计算\n",
    "        pos_id = (mask==1.0).float()\n",
    "        neg_id = (mask==0.0).float()\n",
    "        pos_loss = pos_id * (inputs - targets)**2\n",
    "        neg_loss = neg_id * (inputs)**2\n",
    "        loss = 5.0*pos_loss + 1.0*neg_loss\n",
    "\n",
    "        return loss\n",
    "def compute_loss(pred_conf, pred_cls, pred_txtytwth, targets):\n",
    "    batch_size = pred_conf.size(0)\n",
    "    # 损失函数\n",
    "    conf_loss_function = MSEWithLogitsLoss()\n",
    "    cls_loss_function = nn.CrossEntropyLoss(reduction='none')\n",
    "    txty_loss_function = nn.BCEWithLogitsLoss(reduction='none')\n",
    "    twth_loss_function = nn.MSELoss(reduction='none')\n",
    "\n",
    "    # 预测\n",
    "    pred_conf = pred_conf[..., 0]           # [B, HW,]\n",
    "    pred_cls = pred_cls.permute(0, 2, 1)    # [B, C, HW]\n",
    "    pred_txty = pred_txtytwth[..., :2]      # [B, HW, 2]\n",
    "    pred_twth = pred_txtytwth[..., 2:]      # [B, HW, 2]\n",
    "\n",
    "    # 标签  \n",
    "    gt_conf = targets[..., 0].float()                 # [B, HW,]\n",
    "    gt_obj = targets[..., 1].float()                  # [B, HW,]\n",
    "    gt_cls = targets[..., 2].long()                   # [B, HW,]\n",
    "    gt_txty = targets[..., 3:5].float()               # [B, HW, 2]\n",
    "    gt_twth = targets[..., 5:7].float()               # [B, HW, 2]\n",
    "    gt_box_scale_weight = targets[..., 7]             # [B, HW,]\n",
    "    gt_mask = (gt_box_scale_weight > 0.).float()      # [B, HW,]\n",
    "\n",
    "    # 置信度损失\n",
    "    conf_loss = conf_loss_function(pred_conf, gt_conf, gt_obj)\n",
    "    conf_loss = conf_loss.sum() / batch_size\n",
    "    \n",
    "    # 类别损失\n",
    "    cls_loss = cls_loss_function(pred_cls, gt_cls) * gt_mask\n",
    "    cls_loss = cls_loss.sum() / batch_size\n",
    "    \n",
    "    # 边界框txty的损失\n",
    "    txty_loss = txty_loss_function(pred_txty, gt_txty).sum(-1) * gt_mask * gt_box_scale_weight\n",
    "    txty_loss = txty_loss.sum() / batch_size\n",
    "\n",
    "    # 边界框twth的损失\n",
    "    twth_loss = twth_loss_function(pred_twth, gt_twth).sum(-1) * gt_mask * gt_box_scale_weight\n",
    "    twth_loss = twth_loss.sum() / batch_size\n",
    "    bbox_loss = txty_loss + twth_loss\n",
    "\n",
    "    #总的损失\n",
    "    total_loss = conf_loss + cls_loss + bbox_loss\n",
    "\n",
    "    return conf_loss, cls_loss, bbox_loss, total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c134afb",
   "metadata": {},
   "source": [
    "## 2. YOLO网络定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf7d7f52",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (22223102.py, line 59)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [4], line 59\u001b[0;36m\u001b[0m\n\u001b[0;31m    def set_grid(self, input_size):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class YOLOv2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 cfg,\n",
    "                 device,\n",
    "                 input_size=416,\n",
    "                 num_classes=20,\n",
    "                 trainable=False,\n",
    "                 conf_thresh=0.001, \n",
    "                 nms_thresh=0.6, \n",
    "                 topk=100,\n",
    "                 anchor_size=None):\n",
    "        super(YOLOv2, self).__init__()\n",
    "        self.device = device              # cuda或是cpu \n",
    "        self.input_size = input_size      # 输入图像大小\n",
    "        self.num_classes = num_classes    # 类别数量\n",
    "        self.trainable = trainable        # 训练时标记\n",
    "        self.conf_thresh = conf_thresh    # 置信度阈值\n",
    "        self.nms_thresh = nms_thresh      # NMS阈值\n",
    "        self.stride = cfg['stride']       # 网络最大降采样倍数\n",
    "        self.topk = topk\n",
    "        \n",
    "        # Anchor box config\n",
    "        self.anchor_size = torch.tensor(anchor_size)  # [KA, 2]\n",
    "        self.num_anchors = len(anchor_size)\n",
    "        self.anchor_boxes = self.create_grid(input_size)  # 用于得到最终bbox的参数\n",
    "        \n",
    "        # CBR block\n",
    "        def conv(in_channels, out_channels, kernel_size, strides=1, padding=0):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding, bias=False),\n",
    "                nn.BatchNorm2d(out_channels), nn.ReLU(inplace=True))\n",
    "        \n",
    "        # backbone\n",
    "        self.backbone = models.resnet50(pretrained=trainable)\n",
    "        c5 = 2048\n",
    "        \n",
    "        # neck\n",
    "        self.convsets_1 = nn.Sequential(\n",
    "            conv(c5, 1024, kernel_size=1),\n",
    "            conv(1024, 1024, kernel_size=3, strides=1, padding=1),\n",
    "            conv(1024, 1024, kernel_size=3, strides=1, padding=1))\n",
    "        \n",
    "        # 融合高分辨率的特征信息c4\n",
    "        self.route_layer = conv(1024, 128, kernel_size=1)\n",
    "        self.reorg = reorg_layer(stride=2)\n",
    "        \n",
    "        # head \n",
    "        self.convsets_2 = conv(1024+128*4, 1024, kernel_size=3, strides=1, padding=1)\n",
    "        \n",
    "        # prediction \n",
    "        self.pred = nn.Conv2d(1024, self.num_anchors*(1+4+self.num_classes), kernel_size=1)\n",
    "        \n",
    "        if self.trainable:\n",
    "            self.init_bias()\n",
    "\n",
    "\n",
    "    def init_bias(self):\n",
    "        # init bias\n",
    "        init_prob = 0.01\n",
    "        bias_value = -torch.log(torch.tensor((1. - init_prob) / init_prob))\n",
    "        nn.init.constant_(self.pred.bias[..., :self.num_anchors], bias_value)\n",
    "        nn.init.constant_(self.pred.bias[..., 1*self.num_anchors:(1+self.num_classes)*self.num_anchors], bias_value)\n",
    "\n",
    "    def create_grid(self, input_size):\n",
    "        # 生成一个tensor：grid_xy，每个位置的元素是网格的坐标，\n",
    "        # 这一tensor将在获得边界框参数的时候会用到。\n",
    "        w, h = input_size, input_size\n",
    "        # 生成G矩阵\n",
    "        fmp_w, fmp_h = w // self.stride, h // self.stride\n",
    "        grid_y, grid_x = torch.meshgrid([torch.arange(fmp_h), torch.arange(fmp_w)])\n",
    "        # [H, W, 2] -> [HW, 2]\n",
    "        grid_xy = torch.stack([grid_x, grid_y], dim=-1).float().view(-1, 2)\n",
    "        # [HW, 2] -> [HW, 1, 2] -> [HW, KA, 2]\n",
    "        grid_xy = grid_xy[:, None, :].repeat(1, self.num_anchors, 1)\n",
    "\n",
    "        # [KA, 2] -> [1, KA, 2] -> [HW, KA, 2]\n",
    "        anchor_wh = self.anchor_size[None, :, :].repeat(fmp_h*fmp_w, 1, 1)\n",
    "\n",
    "        # [HW, KA, 4] -> [M, 4]\n",
    "        anchor_boxes = torch.cat([grid_xy, anchor_wh], dim=-1)\n",
    "        anchor_boxes = anchor_boxes.view(-1, 4).to(self.device)\n",
    "\n",
    "        return anchor_boxes        \n",
    "\n",
    "\n",
    "    def set_grid(self, input_size):\n",
    "        # 用于重置grid_xy\n",
    "        self.input_size = input_size\n",
    "        self.anchor_boxes = self.create_grid(input_size)\n",
    "\n",
    "    def decode_boxes(self, anchors, txtytwth_pred):\n",
    "        # 将网络输出的tx,ty,tw,th四个量转换成bbox的(x1,y1),(x2,y2)\n",
    "        \"\"\"将txtytwth预测换算成边界框的左上角点坐标和右下角点坐标 \\n\n",
    "            Input: \\n\n",
    "                txtytwth_pred : [B, H*W*KA, 4] \\n\n",
    "            Output: \\n\n",
    "                x1y1x2y2_pred : [B, H*W*KA, 4] \\n\n",
    "        \"\"\"\n",
    "        # 获得边界框的中心点坐标和宽高\n",
    "        # b_x = sigmoid(tx) + gride_x\n",
    "        # b_y = sigmoid(ty) + gride_y\n",
    "        xy_pred = torch.sigmoid(txtytwth_pred[..., :2]) + anchors[..., :2]\n",
    "        # b_w = anchor_w * exp(tw)\n",
    "        # b_h = anchor_h * exp(th)\n",
    "        wh_pred = torch.exp(txtytwth_pred[..., 2:]) * anchors[..., 2:]\n",
    "\n",
    "        # [B, H*W*KA, 4]\n",
    "        xywh_pred = torch.cat([xy_pred, wh_pred], -1) * self.stride\n",
    "\n",
    "        # 将中心点坐标和宽高换算成边界框的左上角点坐标和右下角点坐标\n",
    "        x1y1x2y2_pred = torch.zeros_like(xywh_pred)\n",
    "        x1y1x2y2_pred[..., :2] = xywh_pred[..., :2] - xywh_pred[..., 2:] * 0.5\n",
    "        x1y1x2y2_pred[..., 2:] = xywh_pred[..., :2] + xywh_pred[..., 2:] * 0.5\n",
    "        \n",
    "        return x1y1x2y2_pred\n",
    "\n",
    "    def nms(self, dets, scores):\n",
    "        # 这是一个最基本的基于python语言的nms操作\n",
    "        # 这一代码来源于Faster RCNN项目\n",
    "        \"\"\"\"Pure Python NMS baseline.\"\"\"\n",
    "        x1 = dets[:, 0]  #xmin\n",
    "        y1 = dets[:, 1]  #ymin\n",
    "        x2 = dets[:, 2]  #xmax\n",
    "        y2 = dets[:, 3]  #ymax\n",
    "\n",
    "        areas = (x2 - x1) * (y2 - y1)                    # bbox的宽w和高h\n",
    "        order = scores.argsort()[::-1]                   # 按照降序对bbox的得分进行排序\n",
    "\n",
    "        keep = []                                        # 用于保存经过筛的最终bbox结果\n",
    "        while order.size > 0:\n",
    "            i = order[0]                                 # 得到最高的那个bbox\n",
    "            keep.append(i)                               \n",
    "            xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "            yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "            xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "            yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "            w = np.maximum(1e-28, xx2 - xx1)\n",
    "            h = np.maximum(1e-28, yy2 - yy1)\n",
    "            inter = w * h\n",
    "\n",
    "            # Cross Area / (bbox + particular area - Cross Area)\n",
    "            ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "            #reserve all the boundingbox whose ovr less than thresh\n",
    "            inds = np.where(ovr <= self.nms_thresh)[0]\n",
    "            order = order[inds + 1]\n",
    "\n",
    "        return keep\n",
    "\n",
    "\n",
    "    def postprocess(self, all_local, all_conf):\n",
    "        # 后处理代码\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            conf_pred: (Tensor) [H*W*KA, 1]\n",
    "            cls_pred:  (Tensor) [H*W*KA, C]\n",
    "            reg_pred:  (Tensor) [H*W*KA, 4]\n",
    "        \"\"\"\n",
    "        anchors = self.anchor_boxes\n",
    "\n",
    "        # (H x W x KA x C,)\n",
    "        scores = (torch.sigmoid(conf_pred) * torch.softmax(cls_pred, dim=-1)).flatten()\n",
    "\n",
    "        # Keep top k top scoring indices only.\n",
    "        num_topk = min(self.topk, reg_pred.size(0))\n",
    "\n",
    "        # torch.sort is actually faster than .topk (at least on GPUs)\n",
    "        predicted_prob, topk_idxs = scores.sort(descending=True)\n",
    "        topk_scores = predicted_prob[:num_topk]\n",
    "        topk_idxs = topk_idxs[:num_topk]\n",
    "\n",
    "        # filter out the proposals with low confidence score\n",
    "        keep_idxs = topk_scores > self.conf_thresh\n",
    "        scores = topk_scores[keep_idxs]\n",
    "        topk_idxs = topk_idxs[keep_idxs]\n",
    "\n",
    "        anchor_idxs = torch.div(topk_idxs, self.num_classes, rounding_mode='floor')\n",
    "        labels = topk_idxs % self.num_classes\n",
    "\n",
    "        reg_pred = reg_pred[anchor_idxs]\n",
    "        anchors = anchors[anchor_idxs]\n",
    "\n",
    "        # 解算边界框, 并归一化边界框: [H*W*KA, 4]\n",
    "        bboxes = self.decode_boxes(anchors, reg_pred)\n",
    "        \n",
    "        # to cpu\n",
    "        scores = scores.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        bboxes = bboxes.cpu().numpy()\n",
    "\n",
    "        # NMS\n",
    "        keep = np.zeros(len(bboxes), dtype=np.int)\n",
    "        for i in range(self.num_classes):\n",
    "            inds = np.where(labels == i)[0]\n",
    "            if len(inds) == 0:\n",
    "                continue\n",
    "            c_bboxes = bboxes[inds]\n",
    "            c_scores = scores[inds]\n",
    "            c_keep = self.nms(c_bboxes, c_scores)\n",
    "            keep[inds[c_keep]] = 1\n",
    "\n",
    "        keep = np.where(keep > 0)\n",
    "        bboxes = bboxes[keep]\n",
    "        scores = scores[keep]\n",
    "        labels = labels[keep]\n",
    "\n",
    "        # 归一化边界框\n",
    "        bboxes = bboxes / self.input_size\n",
    "        bboxes = np.clip(bboxes, 0., 1.)\n",
    "\n",
    "        return bboxes, scores, labels\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def inference(self, x):\n",
    "        # backbone\n",
    "        _, c4, c5 = self.backbone(x)\n",
    "\n",
    "        # neck\n",
    "        p5 = self.convsets_1(c5)\n",
    "        ## 处理c4特征\n",
    "        p4 = self.reorg(self.route_layer(c4))\n",
    "        ## 融合c4特征\n",
    "        p5 = torch.cat([p4,p5], dim=1)\n",
    "\n",
    "        # head\n",
    "        p5 = self.convsets_2(p5)\n",
    "\n",
    "        # prediction\n",
    "        prediction = self.pred(p5)\n",
    "\n",
    "        B, abC, H, W = prediction.size()\n",
    "        KA = self.num_anchors\n",
    "        NC = self.num_classes\n",
    "\n",
    "        # [B, KA * C, H, W] -> [B, H, W, KA * C] -> [B, H*W, KA*C]\n",
    "        prediction = prediction.permute(0, 2, 3, 1).contiguous().view(B, H*W, abC)\n",
    "\n",
    "        # 从pred中分离出objectness预测、类别class预测、bbox的txtytwth预测  \n",
    "        # [B, H*W, KA*C] -> [B, H*W, KA] -> [B, H*W*KA, 1]\n",
    "        conf_pred = prediction[..., :KA].contiguous().view(B, -1, 1)\n",
    "        # [B, H*W, KA*C] -> [B, H*W, KA*NC] -> [B, H*W*KA, NC]\n",
    "        cls_pred = prediction[..., 1*KA : (1+NC)*KA].contiguous().view(B, -1, NC)\n",
    "        # [B, H*W, KA*C] -> [B, H*W, KA*4] -> [B, H*W*KA, 4]\n",
    "        txtytwth_pred = prediction[..., (1+NC)*KA:].contiguous().view(B, -1, 4) \n",
    "        \n",
    "        # 测试时，默认batch为1，\n",
    "        # 因此，我们不需要用batch这个维度，用[0]将其取走。\n",
    "        conf_pred = conf_pred[0]            #[H*W*KA, 1]\n",
    "        cls_pred = cls_pred[0]              #[H*W*KA, NC]\n",
    "        txtytwth_pred = txtytwth_pred[0]    #[H*W*KA, 4]\n",
    "\n",
    "        # 后处理\n",
    "        bboxes, scores, labels = self.postprocess(conf_pred, cls_pred, txtytwth_pred)\n",
    "\n",
    "        return bboxes, scores, labels\n",
    "    \n",
    "    def forward(self, x, target=None):\n",
    "        # 前向推理的代码，主要分为两部分：\n",
    "        # 训练部分：网络得到obj、cls和txtytwth三个分支的预测，然后计算loss；\n",
    "        # 推理部分：输出经过后处理得到的bbox、cls和每个bbox的预测得分。\n",
    "        if not self.trainable:\n",
    "            return self.inference(x)\n",
    "        else:\n",
    "            # backbone\n",
    "            _, c4, c5 = self.backbone(x)\n",
    "\n",
    "            # neck\n",
    "            p5 = self.convsets_1(c5)\n",
    "            ## 处理c4特征\n",
    "            p4 = self.reorg(self.route_layer(c4))\n",
    "            ## 融合c4特征\n",
    "            p5 = torch.cat([p4,p5], dim=1)\n",
    "            \n",
    "            # head\n",
    "            p5 = self.convsets_2(p5)\n",
    "            \n",
    "            # prediction\n",
    "            prediction = self.pred(p5)\n",
    "            \n",
    "            B, abC, H, W = prediction.size()\n",
    "            KA = self.num_anchors\n",
    "            NC = self.num_classes\n",
    "\n",
    "            # [B, KA * C, H, W] -> [B, H, W, KA * C] -> [B, H*W, KA*C]\n",
    "            prediction = prediction.permute(0, 2, 3, 1).contiguous().view(B, H*W, abC)\n",
    "\n",
    "            # 从pred中分离出objectness预测、类别class预测、bbox的txtytwth预测  \n",
    "            # [B, H*W, KA*C] -> [B, H*W, KA] -> [B, H*W*KA, 1]\n",
    "            conf_pred = prediction[..., :KA].contiguous().view(B, -1, 1)\n",
    "            # [B, H*W, KA*C] -> [B, H*W, KA*NC] -> [B, H*W*KA, NC]\n",
    "            cls_pred = prediction[..., 1*KA : (1+NC)*KA].contiguous().view(B, -1, NC)\n",
    "            # [B, H*W, KA*C] -> [B, H*W, KA*4] -> [B, H*W*KA, 4]\n",
    "            txtytwth_pred = prediction[..., (1+NC)*KA:].contiguous().view(B, -1, 4) \n",
    "            \n",
    "            # 添加IoU Loss进入计算\n",
    "            ## 解算边界框\n",
    "            x1y1x2y2_pred = (self.decode_boxes(self.anchor_boxes, txtytwth_pred) / self.input_size).view(-1, 4)\n",
    "            x1y1x2y2_gt = targets[:, :, 7:].view(-1, 4)\n",
    "            ## 计算预测框和真实框之间的IoU\n",
    "            iou_pred = iou_score(x1y1x2y2_pred, x1y1x2y2_gt).view(B, -1, 1)\n",
    "            ## 将IoU作为置信度的学习目标\n",
    "            with torch.no_grad():\n",
    "                gt_conf = iou_pred.clone()\n",
    "            ## 将IoU作为置信度的学习目标 \n",
    "            ## [obj, cls, txtytwth, x1y1x2y2] -> [conf, obj, cls, txtytwth]\n",
    "            targets = torch.cat([gt_conf, targets[:, :, :7]], dim=2)\n",
    "            \n",
    "            # 计算损失\n",
    "            (\n",
    "                conf_loss,\n",
    "                cls_loss,\n",
    "                bbox_loss,\n",
    "                total_loss\n",
    "            ) = compute_loss(\n",
    "                pred_conf=conf_pred, \n",
    "                pred_cls=cls_pred,\n",
    "                pred_txtytwth=txtytwth_pred,\n",
    "                targets=targets,\n",
    "                )\n",
    "\n",
    "            return conf_loss, cls_loss, bbox_loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31665f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型的路径\n",
    "path_to_save = os.path.join(args.save_folder, args.dataset, args.version)\n",
    "os.makedirs(path_to_save, exist_ok=True)\n",
    "\n",
    "print('start trainig, training on', device)\n",
    "\n",
    "# 使用多尺度训练\n",
    "print('use the multi-scale trick ...')\n",
    "train_size = 640\n",
    "val_size = 416\n",
    "\n",
    "# 构建yolov2的配置文件\n",
    "cfg = {\n",
    "        # model\n",
    "        'backbone': 'darknet19',\n",
    "        'pretrained': True,\n",
    "        'stride': 32,  # P5\n",
    "        'reorg_dim': 64,\n",
    "        'head_dim': 1024,\n",
    "        # anchor size\n",
    "        'anchor_size': {\n",
    "            'voc': [[1.19, 1.98], [2.79, 4.59], [4.53, 8.92], [8.06, 5.29], [10.32, 10.65]],\n",
    "            'coco': [[0.53, 0.79], [1.71, 2.36], [2.89, 6.44], [6.33, 3.79], [9.03, 9.74]]\n",
    "            },\n",
    "        # matcher\n",
    "        'ignore_thresh': 0.5,\n",
    "        }\n",
    "\n",
    "# 构建dataset类\n",
    "train_datasets = datasets.VOCDetection(root='../data', year='2012', image_set='train', download=True,\n",
    "                     transform=transforms.Compose([\n",
    "                         transforms.Resize(224),\n",
    "                         transforms.ToTensor(),]))\n",
    "test_dataloader = DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.Resize(224),\n",
    "                      transforms.ToTensor(),\n",
    "                  ])),\n",
    "    batch_size=batch_size_test, shuffle=True, num_workers=num_workers\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt12",
   "language": "python",
   "name": "pt12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
